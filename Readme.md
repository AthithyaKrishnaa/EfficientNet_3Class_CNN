# ğŸ¯ Ultra-Optimized 3-Class Conformal Ensemble
### Cat vs Dog vs Car Classification with 95%+ MCC Target

[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.19-FF6F00?style=flat&logo=tensorflow)](https://www.tensorflow.org/)
[![Python](https://img.shields.io/badge/Python-3.8+-3776AB?style=flat&logo=python&logoColor=white)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/yourusername/yourrepo/blob/main/conformal_3class_ensemble.ipynb)

> **High-reliability image classifier** combining EfficientNet ensemble, Test-Time Augmentation (TTA), and Conformal Prediction for calibrated uncertainty quantification in safety-critical applications.

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Key Features](#-key-features)
- [Architecture](#-architecture)
- [Results](#-results)
- [Installation](#-installation)
- [Usage](#-usage)
- [Methodology](#-methodology)
- [Visualizations](#-visualizations)
- [Citation](#-citation)

---

## ğŸ” Overview

This project implements a **production-grade 3-class image classifier** (Cat / Dog / Car) designed for scenarios requiring:
- **High accuracy** (MCC â‰¥ 0.95)
- **Calibrated uncertainty** quantification
- **Transparent error analysis**
- **Medical-AI-style reliability**

The system uses:
- **Ensemble of 3 EfficientNet models** (2Ã— B0 + 1Ã— B1)
- **Advanced data augmentation** (including Mixup)
- **Test-Time Augmentation** (15Ã— per model = 45 predictions averaged)
- **Conformal Prediction** for coverage guarantees

---

## âœ¨ Key Features

### ğŸ§  Model Architecture
- **Transfer Learning**: Pre-trained EfficientNet backbones (ImageNet)
- **Ensemble Diversity**: Multiple architectures + different random seeds
- **Heavy Regularization**: L2 reg + BatchNorm + Dropout (0.3-0.5)

### ğŸ“Š Data Pipeline
- **4,500 images**: 1,500 per class (Cat, Dog, Car)
- **High resolution**: 128Ã—128 pixels (4Ã— more than baseline)
- **Quality filtering**: Strict variance and brightness thresholds
- **Image enhancement**: Sharpening kernels applied via OpenCV

### ğŸ² Advanced Training
- **Class balancing**: Computed weights for imbalanced datasets
- **Dynamic learning rate**: ReduceLROnPlateau (0.0001 â†’ 1e-7)
- **Early stopping**: Patience-based with best model restoration
- **Augmentation**: Flip, Rotation, Zoom, Translation, Contrast, Brightness + Mixup

### ğŸ”¬ Uncertainty Quantification
- **Conformal Prediction**: Mathematically guaranteed coverage (95%, 90%, 80%)
- **Prediction Sets**: Single-class (certain) vs multi-class (uncertain)
- **Hard Negative Mining**: Automatic identification of difficult cases

---

## ğŸ—ï¸ Architecture

```
Input (128Ã—128Ã—3)
    â†“
Data Augmentation (Keras Sequential)
    â†“
EfficientNet Preprocessing
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Ensemble (3 models)                â”‚
â”‚  â€¢ EfficientNetB0 (seed=42)         â”‚
â”‚  â€¢ EfficientNetB0 (seed=52)         â”‚
â”‚  â€¢ EfficientNetB1 (seed=62)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
GlobalAveragePooling2D
    â†“
Dense(512) + BatchNorm + Dropout(0.5)
    â†“
Dense(256) + BatchNorm + Dropout(0.3)
    â†“
Dense(3, softmax)
    â†“
Test-Time Augmentation (15Ã—)
    â†“
Ensemble Averaging (3 models)
    â†“
Conformal Prediction Sets
```

---

## ğŸ“ˆ Results

### Overall Performance

| Metric | Baseline (Single) | Ensemble (TTA) | Conformal (90%) |
|--------|------------------|----------------|-----------------|
| **Accuracy** | 85-90% | 94.4% | 94.4% |
| **MCC** | 0.905 | **0.917** | **0.917** |
| **Coverage** | N/A | N/A | 94.4% (target: 90%) |

### Per-Class Metrics

| Class | Sensitivity | Specificity | Precision | F1-Score | MCC |
|-------|------------|-------------|-----------|----------|-----|
| **Cat** | 0.889 | 0.972 | 0.941 | 0.914 | 0.874 |
| **Dog** | 0.944 | 0.944 | 0.895 | 0.919 | 0.877 |
| **Car** | 1.000 | 1.000 | 1.000 | 1.000 | 1.000 |

### Confusion Matrix

```
           Predicted
           Cat  Dog  Car
Actual Cat [160  20   0]   89% recall
       Dog [ 10 170   0]   94% recall
       Car [  0   0 180]  100% recall
```

**Key Insights:**
- âœ… **Car class**: Perfect separation (0 errors)
- âš ï¸ **Catâ†”Dog confusion**: All 30 errors occur between animal classes
- ğŸ¯ **Total errors**: 30/540 (5.6% error rate)

---

## ğŸš€ Installation

### Prerequisites
```bash
Python 3.8+
TensorFlow 2.x
CUDA 11.x (for GPU support)
```

### Setup

#### Option 1: Google Colab (Recommended)
Click the badge at the top to open directly in Colab. All dependencies pre-installed!

#### Option 2: Local Installation
```bash
# Clone repository
git clone https://github.com/yourusername/conformal-3class-ensemble.git
cd conformal-3class-ensemble

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Requirements.txt
```txt
tensorflow>=2.19.0
numpy>=1.23.0
matplotlib>=3.5.0
seaborn>=0.12.0
scikit-learn>=1.2.0
opencv-python>=4.7.0
Pillow>=9.4.0
requests>=2.28.0
```

---

## ğŸ’» Usage

### Quick Start

```python
# Run the complete pipeline
jupyter notebook conformal_3class_ensemble.ipynb
```

### Step-by-Step Execution

```python
# 1. Data Loading (automatic download)
# Downloads Microsoft Cats&Dogs + CIFAR-10 Car images

# 2. Training Ensemble
# Trains 3 models with different architectures/seeds
# Expected time: 30-60 minutes on GPU

# 3. Evaluation with TTA
# 45 predictions per sample (3 models Ã— 15 augmentations)
# Expected time: 5-7 minutes

# 4. Conformal Prediction
# Computes prediction sets at 95%, 90%, 80% confidence

# 5. Generate Visualizations
# Creates 4 comprehensive analysis figures
```

### Custom Dataset

```python
# Modify data loading function
def load_custom_images(path, label, max_images=1500):
    images, labels = [], []
    for filename in os.listdir(path):
        img = keras.preprocessing.image.load_img(
            os.path.join(path, filename),
            target_size=(128, 128)
        )
        img_array = keras.preprocessing.image.img_to_array(img) / 255.0
        images.append(img_array)
        labels.append(label)
    return images, labels
```

---

## ğŸ”¬ Methodology

### 1. Data Preparation
- **Sources**: 
  - Cats/Dogs: [Microsoft PetImages](https://www.microsoft.com/en-us/download/details.aspx?id=54765)
  - Cars: CIFAR-10 "automobile" class
- **Preprocessing**:
  - Resize to 128Ã—128
  - Normalize to [0,1]
  - Quality filtering (std > 0.04, mean > 0.12)
  - Sharpening kernel application

### 2. Model Training
- **Optimizer**: Adam (lr=1e-4)
- **Loss**: Sparse categorical crossentropy
- **Callbacks**: 
  - EarlyStopping (patience=12, monitor=val_loss)
  - ReduceLROnPlateau (factor=0.5, patience=5)
  - ModelCheckpoint (save best on val_accuracy)
- **Epochs**: Up to 60 (typically stops at ~45-50)
- **Batch size**: 32

### 3. Test-Time Augmentation
For each test sample:
```
Original prediction
+ 14 augmented predictions (flip, rotate, zoom, etc.)
= Average of 15 predictions per model
Ã— 3 models in ensemble
= 45 total predictions averaged
```

### 4. Conformal Prediction
**Algorithm**:
1. Compute non-conformity scores on calibration set:
   ```
   score = 1 - P(true_class)
   ```
2. For significance level Î± (e.g., 0.10 for 90% confidence):
   ```
   threshold = quantile(scores, (n+1)(1-Î±)/n)
   ```
3. Build prediction set for test sample:
   ```
   Include class k if: 1 - P(k) â‰¤ threshold
   ```

**Properties**:
- âœ… Coverage guarantee: â‰¥ (1-Î±) with high probability
- âœ… Distribution-free: no assumptions about data
- âœ… Post-hoc: works with any trained model

---

## ğŸ“Š Visualizations

The notebook generates 4 comprehensive figures:

### 1. Confusion Matrix
![Confusion Matrix](images/confusion_matrix.png)
*Annotated heatmap showing class-wise predictions with overall accuracy and MCC*

### 2. Performance Metrics
![Performance Metrics](images/performance_metrics.png)
*Four subplots: (a) Per-class metrics, (b) Conformal coverage, (c) Set size distribution, (d) MCC comparison*

### 3. Error Analysis
![Error Analysis](images/error_analysis.png)
*Three subplots: (a) False negatives by class, (b) Confusion patterns, (c) Confidence distributions*

### 4. Sample Predictions
![Sample Predictions](images/sample_predictions.png)
*Visual grid showing: high/low confidence correct, wrong predictions, conformal ambiguous cases*

---

## ğŸ“ Project Structure

```
conformal-3class-ensemble/
â”‚
â”œâ”€â”€ conformal_3class_ensemble.ipynb   # Main notebook
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ LICENSE                            # MIT License
â”‚
â”œâ”€â”€ images/                            # Generated visualizations
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”œâ”€â”€ performance_metrics.png
â”‚   â”œâ”€â”€ error_analysis.png
â”‚   â””â”€â”€ sample_predictions.png
â”‚
â”œâ”€â”€ models/                            # Saved trained models
â”‚   â”œâ”€â”€ best_model_b0_1.keras
â”‚   â”œâ”€â”€ best_model_b0_2.keras
â”‚   â””â”€â”€ best_model_b1.keras
â”‚
â””â”€â”€ data/                              # Downloaded datasets (auto-created)
    â”œâ”€â”€ PetImages/
    â”‚   â”œâ”€â”€ Cat/
    â”‚   â””â”€â”€ Dog/
    â””â”€â”€ CarImages/
```

---

## ğŸ“ Key Concepts Explained

### Matthews Correlation Coefficient (MCC)
- **Range**: -1 to +1
- **Interpretation**: 
  - +1 = perfect prediction
  - 0 = random guessing
  - -1 = perfect disagreement
- **Advantage**: Balanced metric for multi-class problems, accounts for all TP/TN/FP/FN

### Conformal Prediction
- **Purpose**: Provide calibrated uncertainty with mathematical guarantees
- **Output**: Prediction sets (not just point predictions)
- **Guarantee**: Coverage â‰¥ (1-Î±) regardless of data distribution
- **Use case**: Medical AI, autonomous vehicles, high-stakes decisions

### Test-Time Augmentation
- **Idea**: Apply augmentations during inference, not just training
- **Benefit**: Reduces variance, improves robustness
- **Trade-off**: Slower inference (15Ã— slower in our case)

---

## ğŸš€ Improvements & Future Work

### Short-term (MCC 0.95+ target)
- [ ] Increase ensemble to 5 models
- [ ] Use EfficientNetB2/B3 (larger backbones)
- [ ] Add focal loss for hard examples
- [ ] Implement class-conditional augmentation

### Long-term
- [ ] Add Grad-CAM for interpretability
- [ ] Implement active learning loop
- [ ] Deploy as REST API (FastAPI + Docker)
- [ ] Add A/B testing framework
- [ ] Create web demo (Streamlit/Gradio)

---

## ğŸ¤ Contributing

Contributions welcome! Please:
1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“ Citation

If you use this code in your research, please cite:

```bibtex
@misc{conformal3class2025,
  author = {Your Name},
  title = {Ultra-Optimized 3-Class Conformal Ensemble for Image Classification},
  year = {2025},
  publisher = {GitHub},
  url = {https://github.com/yourusername/conformal-3class-ensemble}
}
```

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **EfficientNet**: Mingxing Tan and Quoc V. Le ([paper](https://arxiv.org/abs/1905.11946))
- **Conformal Prediction**: Vovk et al. ([book](https://link.springer.com/book/10.1007/978-3-031-06649-8))
- **Microsoft PetImages**: [Kaggle Cats and Dogs Dataset](https://www.microsoft.com/en-us/download/details.aspx?id=54765)
- **CIFAR-10**: Alex Krizhevsky ([dataset](https://www.cs.toronto.edu/~kriz/cifar.html))

---

## ğŸ“§ Contact

**Your Name** - [@yourtwitter](https://twitter.com/yourtwitter) - your.email@example.com

Project Link: [https://github.com/yourusername/conformal-3class-ensemble](https://github.com/yourusername/conformal-3class-ensemble)

---

<p align="center">
  Made with â¤ï¸ for reliable AI
</p>
